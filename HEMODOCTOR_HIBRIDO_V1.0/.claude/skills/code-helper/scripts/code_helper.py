#!/usr/bin/env python3
"""
Claude Code Helper - Quick Automation Scripts
Generate boilerplate code for common HemoDoctor tasks
"""

import sys
from pathlib import Path


def generate_yaml_parser():
    """Generate YAML parser boilerplate"""
    code = '''#!/usr/bin/env python3
"""
YAML Parser for HemoDoctor
Generated by claude-code-helper
"""

import yaml
from pathlib import Path
from typing import Dict, List, Any


def load_yaml(file_path: str) -> Dict:
    """Load and parse YAML file"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def save_yaml(data: Dict, file_path: str):
    """Save data to YAML file"""
    with open(file_path, 'w', encoding='utf-8') as f:
        yaml.dump(data, f, default_flow_style=False, allow_unicode=True)


def main():
    if len(sys.argv) < 2:
        print("Usage: python parser.py <yaml_file>")
        sys.exit(1)
    
    yaml_file = sys.argv[1]
    data = load_yaml(yaml_file)
    
    # TODO: Process data here
    print(f"Loaded {len(data)} top-level keys")
    for key in data.keys():
        print(f"  - {key}")


if __name__ == "__main__":
    import sys
    main()
'''
    return code


def generate_pytest_template():
    """Generate pytest test template"""
    code = '''#!/usr/bin/env python3
"""
Test Template for HemoDoctor
Generated by claude-code-helper
"""

import pytest
from your_module import your_function  # TODO: Replace with actual imports


class TestYourModule:
    """Test suite for YourModule"""
    
    def setup_method(self):
        """Setup before each test"""
        # TODO: Initialize test fixtures
        pass
    
    def test_basic_functionality(self):
        """Test basic functionality"""
        # TODO: Implement test
        result = your_function(input_data)
        assert result == expected_output
    
    def test_edge_case(self):
        """Test edge case"""
        # TODO: Implement edge case test
        with pytest.raises(ValueError):
            your_function(invalid_input)
    
    def test_with_missing_data(self):
        """Test with missing data"""
        # TODO: Test missingness handling
        incomplete_input = {"hb": 9.5, "mcv": None}
        result = your_function(incomplete_input)
        assert result is not None


def test_integration():
    """Integration test"""
    # TODO: Test full pipeline
    pass


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
'''
    return code


def generate_csv_processor():
    """Generate CSV processor boilerplate"""
    code = '''#!/usr/bin/env python3
"""
CSV Processor for HemoDoctor
Generated by claude-code-helper
"""

import csv
import json
from pathlib import Path
from typing import List, Dict


def load_csv(file_path: str) -> List[Dict]:
    """Load CSV file into list of dicts"""
    cases = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            # Convert numeric fields
            case = {}
            for key, value in row.items():
                if value:
                    # Try to convert to number
                    try:
                        case[key] = float(value)
                    except ValueError:
                        case[key] = value
                else:
                    case[key] = None
            
            cases.append(case)
    
    return cases


def save_csv(data: List[Dict], file_path: str):
    """Save list of dicts to CSV"""
    if not data:
        print("No data to save")
        return
    
    fieldnames = data[0].keys()
    
    with open(file_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)


def main():
    if len(sys.argv) < 2:
        print("Usage: python csv_processor.py <input.csv> [output.json]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "output.json"
    
    # Load CSV
    cases = load_csv(input_file)
    print(f"Loaded {len(cases)} cases")
    
    # TODO: Process cases here
    
    # Save as JSON
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(cases, f, indent=2)
    
    print(f"Saved to {output_file}")


if __name__ == "__main__":
    import sys
    main()
'''
    return code


def generate_batch_processor():
    """Generate batch processing template"""
    code = '''#!/usr/bin/env python3
"""
Batch Processor for HemoDoctor
Generated by claude-code-helper
"""

import json
from pathlib import Path
from typing import List, Dict
from concurrent.futures import ProcessPoolExecutor, as_completed


def process_single_case(case: Dict) -> Dict:
    """Process a single case"""
    # TODO: Implement your processing logic
    result = {
        'case_id': case.get('case_id', 'unknown'),
        'input': case,
        'output': None,  # TODO: Add output
        'status': 'success'
    }
    
    return result


def process_batch(cases: List[Dict], max_workers: int = 4) -> List[Dict]:
    """Process multiple cases in parallel"""
    results = []
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        futures = {executor.submit(process_single_case, case): case 
                  for case in cases}
        
        # Collect results as they complete
        for i, future in enumerate(as_completed(futures), 1):
            try:
                result = future.result()
                results.append(result)
                print(f"Processed {i}/{len(cases)}: {result['case_id']}")
            except Exception as e:
                case = futures[future]
                print(f"Error processing {case.get('case_id', 'unknown')}: {e}")
                results.append({
                    'case_id': case.get('case_id', 'unknown'),
                    'status': 'error',
                    'error': str(e)
                })
    
    return results


def main():
    if len(sys.argv) < 2:
        print("Usage: python batch_processor.py <input.json> [output.json] [--workers=4]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "batch_results.json"
    
    # Parse workers argument
    workers = 4
    for arg in sys.argv:
        if arg.startswith('--workers='):
            workers = int(arg.split('=')[1])
    
    # Load input
    with open(input_file, 'r') as f:
        cases = json.load(f)
    
    print(f"Processing {len(cases)} cases with {workers} workers...")
    
    # Process
    results = process_batch(cases, max_workers=workers)
    
    # Save results
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    # Summary
    success = sum(1 for r in results if r['status'] == 'success')
    errors = len(results) - success
    
    print(f"\\nDone!")
    print(f"  Success: {success}")
    print(f"  Errors: {errors}")
    print(f"  Output: {output_file}")


if __name__ == "__main__":
    import sys
    main()
'''
    return code


def generate_quick_stats():
    """Generate quick stats calculator"""
    code = '''#!/usr/bin/env python3
"""
Quick Stats Calculator for HemoDoctor
Generated by claude-code-helper
"""

import json
from collections import Counter
from typing import List, Dict


def calculate_stats(cases: List[Dict]):
    """Calculate statistics from cases"""
    print("="*60)
    print("QUICK STATISTICS")
    print("="*60)
    
    print(f"\\nTotal cases: {len(cases)}")
    
    # Count by syndrome
    if 'ground_truth_syndrome' in cases[0]:
        syndromes = Counter(c['ground_truth_syndrome'] for c in cases)
        print(f"\\nBy syndrome:")
        for syndrome, count in syndromes.most_common():
            pct = count / len(cases) * 100
            print(f"  {syndrome}: {count} ({pct:.1f}%)")
    
    # Count by priority
    if 'ground_truth_priority' in cases[0]:
        priorities = Counter(c['ground_truth_priority'] for c in cases)
        print(f"\\nBy priority:")
        for priority, count in priorities.most_common():
            pct = count / len(cases) * 100
            print(f"  {priority}: {count} ({pct:.1f}%)")
    
    # Numeric field stats
    numeric_fields = ['hb', 'mcv', 'wbc', 'plt']
    print(f"\\nNumeric field ranges:")
    
    for field in numeric_fields:
        values = [c[field] for c in cases if c.get(field) is not None]
        if values:
            print(f"  {field}: {min(values):.1f} - {max(values):.1f}")
    
    print("="*60)


def main():
    if len(sys.argv) < 2:
        print("Usage: python quick_stats.py <input.json>")
        sys.exit(1)
    
    input_file = sys.argv[1]
    
    with open(input_file, 'r') as f:
        cases = json.load(f)
    
    calculate_stats(cases)


if __name__ == "__main__":
    import sys
    main()
'''
    return code


def main():
    if len(sys.argv) < 2:
        print("Usage: python code_helper.py <template> [output_file]")
        print("\\nTemplates:")
        print("  yaml-parser     - YAML parser boilerplate")
        print("  pytest          - Pytest test template")
        print("  csv-processor   - CSV to JSON converter")
        print("  batch-processor - Parallel batch processing")
        print("  quick-stats     - Quick statistics calculator")
        print("\\nExamples:")
        print("  python code_helper.py yaml-parser parser.py")
        print("  python code_helper.py pytest test_module.py")
        sys.exit(1)
    
    template = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    # Generate code
    generators = {
        'yaml-parser': generate_yaml_parser,
        'pytest': generate_pytest_template,
        'csv-processor': generate_csv_processor,
        'batch-processor': generate_batch_processor,
        'quick-stats': generate_quick_stats
    }
    
    if template not in generators:
        print(f"❌ Unknown template: {template}")
        print(f"Available: {', '.join(generators.keys())}")
        sys.exit(1)
    
    code = generators[template]()
    
    # Output
    if output_file:
        with open(output_file, 'w') as f:
            f.write(code)
        print(f"✅ Generated {template} template → {output_file}")
    else:
        print(code)


if __name__ == "__main__":
    main()
